{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "os.getpid()\n",
    "\n",
    "sys.path.append(\"../sketchformer\")\n",
    "sys.path.append(\"../src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isketcher import InteractiveSketcher\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 5617, valid: 535, test: 1113\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "with open('../data/isketcher/train.json', 'r') as f:\n",
    "    train = json.load(f)\n",
    "with open('../data/isketcher/valid.json', 'r') as f:\n",
    "    valid = json.load(f)\n",
    "with open('../data/isketcher/test.json', 'r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "print(f\"train: {len(train)}, valid: {len(valid)}, test: {len(test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[run-experiment] resorting checkpoint if exists\n",
      "[Checkpoint] Restored, step #207536\n"
     ]
    }
   ],
   "source": [
    "# load sketchformer\n",
    "from basic_usage.sketchformer import continuous_embeddings\n",
    "sketchformer = continuous_embeddings.get_pretrained_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "['airplane', 'apple', 'hot air balloon', 'banana', 'basket', 'bee', 'bench', 'bicycle', 'bird', 'wine bottle', 'bucket', 'bus', 'butterfly', 'car', 'cat', 'chair', 'cloud', 'cow', 'cup', 'dog', 'duck', 'fence', 'flower', 'grapes', 'grass', 'horse', 'house', 'moon', 'mountain', 'face', 'pig', 'rabbit', 'sheep', 'star', 'streetlight', 'sun', 'table', 'tree', 'truck', 'umbrella']\n",
      "{'airplane': 0, 'apple': 1, 'hot air balloon': 2, 'banana': 3, 'basket': 4, 'bee': 5, 'bench': 6, 'bicycle': 7, 'bird': 8, 'wine bottle': 9, 'bucket': 10, 'bus': 11, 'butterfly': 12, 'car': 13, 'cat': 14, 'chair': 15, 'cloud': 16, 'cow': 17, 'cup': 18, 'dog': 19, 'duck': 20, 'fence': 21, 'flower': 22, 'grapes': 23, 'grass': 24, 'horse': 25, 'house': 26, 'moon': 27, 'mountain': 28, 'face': 29, 'pig': 30, 'rabbit': 31, 'sheep': 32, 'star': 33, 'streetlight': 34, 'sun': 35, 'table': 36, 'tree': 37, 'truck': 38, 'umbrella': 39}\n"
     ]
    }
   ],
   "source": [
    "# load class label\n",
    "df = pd.read_csv('../outputs/sketchyscene_quickdraw.csv')\n",
    "df = df.dropna(subset=['quickdraw_label'])\n",
    "class_names = []\n",
    "for row in df.itertuples():\n",
    "    class_names.append(row.quickdraw_label)\n",
    "class_to_num = dict(zip(class_names, range(0, len(class_names))))\n",
    "\n",
    "print(len(class_names))\n",
    "print(class_names)\n",
    "print(class_to_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocess\n",
    "def preprocess(dataset):\n",
    "    input_batch = []\n",
    "    label_batch = []\n",
    "    for scene in tqdm(dataset):\n",
    "        sketches = list(map(lambda o: o['sketch'], scene))\n",
    "        sketch_embeddings = sketchformer.get_embeddings(sketches)\n",
    "        input_scene = []\n",
    "        labels = []\n",
    "        for se, obj in zip(sketch_embeddings, scene):\n",
    "            p = [obj['position'][0] / 750, obj['position'][1] / 750]\n",
    "            o = se.numpy().tolist() + p\n",
    "            input_scene.append(o)  # オブジェクトの数が不規則\n",
    "            labels.append(class_to_num[obj['label']])  # convert to num\n",
    "        input_batch.append(input_scene)\n",
    "        label_batch.append(labels)\n",
    "    return tf.ragged.constant(input_batch).to_tensor(0.), tf.ragged.constant(label_batch).to_tensor(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # アテンション・ロジットにパディングを追加するため\n",
    "    # さらに次元を追加する\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    # Encoderパディング・マスク\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # デコーダーの 2つ目のアテンション・ブロックで使用\n",
    "    # このパディング・マスクはエンコーダーの出力をマスクするのに使用\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # デコーダーの 1つ目のアテンション・ブロックで使用\n",
    "    # デコーダーが受け取った入力のパディングと将来のトークンをマスクするのに使用\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "\n",
    "def create_combined_mask(tar):\n",
    "\n",
    "    # デコーダーの 1つ目のアテンション・ブロックで使用\n",
    "    # デコーダーが受け取った入力のパディングと将来のトークンをマスクするのに使用\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return combined_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "# TODO: adjust parameters\n",
    "\n",
    "num_layers = 4\n",
    "d_model = 130\n",
    "dff = 512\n",
    "num_heads = 5\n",
    "\n",
    "target_object_num = 40  # object num\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# Optimizer\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "interactive_sketcher = InteractiveSketcher(\n",
    "    num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff,\n",
    "    object_num=target_object_num, pe_target=100, rate=dropout_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "# checkpoint\n",
    "\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=interactive_sketcher,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# チェックポイントが存在したなら、最後のチェックポイントを復元\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/' + 'train/' + current_time\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "valid_log_dir = 'logs/' + 'valid/' + current_time\n",
    "valid_summary_writer = tf.summary.create_file_writer(valid_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "print(\"Preprocessing train dataset\")\n",
    "x_train, y_train = preprocess(train)\n",
    "print(\"Preprocessing valid dataset\")\n",
    "x_valid, y_valid = preprocess(valid)\n",
    "print(\"Preprocessing test dataset\")\n",
    "x_test, y_test = preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training step\n",
    "\n",
    "\n",
    "scc = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    reduction=tf.keras.losses.Reduction.NONE)\n",
    "mse = tf.keras.losses.MeanSquaredError(\n",
    "    reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_class_accuracy')\n",
    "\n",
    "valid_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_class_accuracy')\n",
    "\n",
    "# @tf.functionは高速に実行するためにtrain_stepをTFグラフにトレースコンパイルします。\n",
    "# この関数は、引数となるテンソルのshapeに特化したものです。\n",
    "# シーケンスの長さや（最後のバッチが小さくなるなど）バッチサイズが可変となることによって\n",
    "# 再トレーシングが起きないようにするため、input_signatureを使って、より一般的なshapeを\n",
    "# 指定します。\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None, None), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None, None, None), dtype=tf.float32),\n",
    "]\n",
    "\n",
    "def loss_function(c_real, x_real, y_real, c_pred, x_pred, y_pred):\n",
    "    # class loss\n",
    "    # クラスラベルはカテゴリカルクロスエントロピー\n",
    "    c_loss_ = scc(c_real, c_pred)\n",
    "\n",
    "    # position loss\n",
    "    # 位置座標は平均二乗誤差\n",
    "    p_loss_ = tf.math.square(x_real - x_pred) + \\\n",
    "        tf.math.square(y_real - y_pred)\n",
    "\n",
    "    # mask padded object\n",
    "    # パディングしたオブジェクトの部分を損失に加えないようにマスクする\n",
    "    mask = tf.math.logical_not(tf.math.equal(c_real, 0))\n",
    "    c_mask = tf.cast(mask, dtype=c_loss_.dtype)\n",
    "    c_loss = tf.reduce_mean(c_loss_ * c_mask)\n",
    "    p_mask = tf.cast(mask, dtype=p_loss_.dtype)\n",
    "    p_loss = tf.reduce_mean(p_loss_ * p_mask)\n",
    "    \n",
    "    return c_loss + p_loss\n",
    "\n",
    "# @tf.function(input_signature=train_step_signature) # なぜか通らないため一旦コメントアウト\n",
    "def train_step(tar, labels):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    x_real, y_real = tar_real[:, :, -2], tar_real[:, :, -1]\n",
    "\n",
    "    labels_inp = labels[:, :-1]\n",
    "    labels_real = labels[:, 1:]\n",
    "\n",
    "    # パディングしたオブジェクトの位置はlabelsが0の位置のため、そこからマスクを作成\n",
    "    combined_mask = create_combined_mask(labels_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        c_out, x_out, y_out, _ = interactive_sketcher(\n",
    "            tar_inp, True, combined_mask)\n",
    "        \n",
    "        loss = loss_function(labels_real, x_real, y_real, c_out, x_out, y_out)\n",
    "\n",
    "    gradients = tape.gradient(loss, interactive_sketcher.trainable_variables)\n",
    "    optimizer.apply_gradients(\n",
    "        zip(gradients, interactive_sketcher.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels_real, c_out)\n",
    "\n",
    "def valid_step(tar, labels):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    x_real, y_real = tar_real[:, :, -2], tar_real[:, :, -1]\n",
    "\n",
    "    labels_inp = labels[:, :-1]\n",
    "    labels_real = labels[:, 1:]\n",
    "\n",
    "    # パディングしたオブジェクトの位置はlabelsが0の位置のため、そこからマスクを作成\n",
    "    combined_mask = create_combined_mask(labels_inp)\n",
    "\n",
    "    c_out, x_out, y_out, _ = interactive_sketcher(\n",
    "        tar_inp, False, combined_mask)\n",
    "    \n",
    "    loss = loss_function(labels_real, x_real, y_real, c_out, x_out, y_out)\n",
    "\n",
    "    valid_loss(loss)\n",
    "    valid_accuracy(labels_real, c_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx: min(ndx + n, l)]\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    valid_loss.reset_states()\n",
    "    valid_accuracy.reset_states()\n",
    "\n",
    "    # train\n",
    "    for i, (x_batch, y_batch) in enumerate(batch(zip(x_train, y_train), BATCH_SIZE)):\n",
    "        train_step(x_batch, y_batch)\n",
    "\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "                epoch + 1, i + 1, train_loss.result(), train_accuracy.result()))\n",
    "\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "    # valid\n",
    "    valid_step(x_valid, y_valid)\n",
    "\n",
    "    with valid_summary_writer.as_default():\n",
    "        tf.summary.scalar('val_loss', valid_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('val_accuracy', valid_accuracy.result(), step=epoch)\n",
    "\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print('Saving checkpoint for epoch {} at {}'.format(epoch + 1,\n",
    "                                                            ckpt_save_path))\n",
    "\n",
    "    print('Epoch {} Loss {:.4f} Accuracy {:.4f} Valid_Loss {:.4f} Valid_Accuracy {:.4f}'.format(\n",
    "        epoch + 1, train_loss.result(), train_accuracy.result(), valid_loss.result(), valid_accuracy.result()))\n",
    "\n",
    "    print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 0 -------\n",
      "real label:  cloud\n",
      "real position:  [80, 55]\n",
      "---- 1 -------\n",
      "real label:  cloud\n",
      "pred label:  grass\n",
      "real position:  [330, 55]\n",
      "pred position:  [373.57, 471.98]\n",
      "---- 2 -------\n",
      "real label:  fence\n",
      "pred label:  grass\n",
      "real position:  [480, 335]\n",
      "pred position:  [372.19, 492.52]\n",
      "---- 3 -------\n",
      "real label:  fence\n",
      "pred label:  grass\n",
      "real position:  [720, 335]\n",
      "pred position:  [360.95, 467.97]\n",
      "---- 4 -------\n",
      "real label:  mountain\n",
      "pred label:  grass\n",
      "real position:  [275, 180]\n",
      "pred position:  [345.43, 438.94]\n",
      "---- 5 -------\n",
      "real label:  cloud\n",
      "pred label:  grass\n",
      "real position:  [610, 70]\n",
      "pred position:  [347.45, 439.75]\n",
      "---- 6 -------\n",
      "real label:  house\n",
      "pred label:  grass\n",
      "real position:  [620, 320]\n",
      "pred position:  [391.66, 485.33]\n",
      "---- 7 -------\n",
      "real label:  fence\n",
      "pred label:  grass\n",
      "real position:  [60, 335]\n",
      "pred position:  [396.86, 482.74]\n",
      "---- 8 -------\n",
      "real label:  car\n",
      "pred label:  grass\n",
      "real position:  [415, 535]\n",
      "pred position:  [400.46, 486.73]\n",
      "---- 9 -------\n",
      "real label:  fence\n",
      "pred label:  grass\n",
      "real position:  [190, 335]\n",
      "pred position:  [400.91, 485.74]\n",
      "---- 10 -------\n",
      "real label:  fence\n",
      "pred label:  grass\n",
      "real position:  [335, 335]\n",
      "pred position:  [403.31, 493.65]\n",
      "---- 11 -------\n",
      "real label:  tree\n",
      "pred label:  grass\n",
      "real position:  [735, 490]\n",
      "pred position:  [403.31, 493.65]\n",
      "---- 12 -------\n",
      "real label:  tree\n",
      "pred label:  grass\n",
      "real position:  [640, 625]\n",
      "pred position:  [403.31, 493.65]\n",
      "---- 13 -------\n",
      "real label:  tree\n",
      "pred label:  grass\n",
      "real position:  [415, 365]\n",
      "pred position:  [403.31, 493.65]\n",
      "---- 14 -------\n",
      "real label:  tree\n",
      "pred label:  grass\n",
      "real position:  [260, 370]\n",
      "pred position:  [403.31, 493.65]\n",
      "---- 15 -------\n",
      "real label:  tree\n",
      "pred label:  grass\n",
      "real position:  [95, 370]\n",
      "pred position:  [403.31, 493.65]\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "\n",
    "scene_index = 0\n",
    "\n",
    "print(\"----\", 0, \"-------\")\n",
    "print(\"real label: \", test[scene_index][0][\"label\"])\n",
    "print(\"real position: \", test[scene_index][0][\"position\"])\n",
    "\n",
    "for i in range(1, len(test[scene_index])):\n",
    "\n",
    "    c_out, x_out, y_out, _ = interactive_sketcher(\n",
    "        x[:, :i], training=False, look_ahead_mask=None)\n",
    "\n",
    "    print(\"----\", i, \"-------\")\n",
    "    print(\"real label: \", test[scene_index][i][\"label\"])\n",
    "    print(\"pred label: \", class_names[tf.argmax(c_out[scene_index][0])])\n",
    "\n",
    "    print(\"real position: \", test[scene_index][i][\"position\"])\n",
    "    print(\"pred position:  [{0}, {1}]\".format(round(x_out[scene_index][0].numpy(\n",
    "    ) * 750, 2), round(y_out[scene_index][0].numpy() * 750, 2)))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45ddb2f520d5841844bae62ac6ba90fc4ad0236a720fe6a2974c193e3d0c3fbd"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('i-sketcher': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
